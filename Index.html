<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>WebAR Wall Placement</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.160.0/examples/js/loaders/GLTFLoader.js"></script>
</head>
<body style="margin: 0; overflow: hidden;">
  <!-- Overlay: Initial instruction image -->
  <img id="instruction" src="Firstimage.png" style="
    position: absolute; width: 100vw; height: 100vh;
    object-fit: cover; opacity: 0.7; z-index: 5;" />

  <!-- Overlay: Headphone icon -->
  <img id="headphone" src="earphone.png" style="
    position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
    width: 128px; height: auto; opacity: 0; z-index: 6; transition: opacity 1s;" />

  <script>
    let camera, scene, renderer;
    let controller;
    let reticle;
    let model;
    let audio;

    const clock = new THREE.Clock();
    let mixer;

    // Audio setup
    const audioListener = new THREE.AudioListener();
    const sound = new THREE.Audio(audioListener);
    const audioLoader = new THREE.AudioLoader();

    // Instruction fadeout after tap
    function fadeOutInstruction() {
      const img = document.getElementById("instruction");
      if (img) img.style.display = "none";
    }

    function fadeHeadphoneIn() {
      const icon = document.getElementById("headphone");
      icon.style.opacity = 0.7;
      setTimeout(() => {
        icon.style.opacity = 0;
      }, 5000); // 1s fade in + 4s stay
    }

    function loadModel(position, rotation) {
      const loader = new THREE.GLTFLoader();
      loader.load('PortalANimMus-02.glb', gltf => {
        model = gltf.scene;
        model.position.copy(position);
        model.quaternion.copy(rotation);
        model.translateZ(-0.5); // offset 50cm in front of wall
        scene.add(model);

        mixer = new THREE.AnimationMixer(model);
        gltf.animations.forEach(clip => {
          const action = mixer.clipAction(clip);
          action.play();
          action.loop = THREE.LoopRepeat;
        });

        setTimeout(() => {
          audioLoader.load('museumversion_250709.mp3', buffer => {
            sound.setBuffer(buffer);
            sound.setLoop(true);
            sound.setVolume(1);
            sound.play();
          });
        }, 100); // slight delay after animation starts
      });
    }

    async function init() {
      const canvas = document.createElement('canvas');
      document.body.appendChild(canvas);

      renderer = new THREE.WebGLRenderer({ canvas, alpha: true });
      renderer.xr.enabled = true;
      document.body.appendChild(renderer.domElement);

      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera();
      camera.add(audioListener);
      scene.add(camera);

      const light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1);
      scene.add(light);

      document.body.appendChild(ARButton.createButton(renderer, { requiredFeatures: ['hit-test'] }));

      const session = await navigator.xr.requestSession('immersive-ar', { requiredFeatures: ['hit-test'] });
      renderer.xr.setSession(session);

      const referenceSpace = await session.requestReferenceSpace('local');
      const viewerSpace = await session.requestReferenceSpace('viewer');
      const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

      controller = renderer.xr.getController(0);
      controller.addEventListener('select', (event) => {
        const frame = event.data?.frame;
        const referenceSpace = renderer.xr.getReferenceSpace();
        if (!frame || !hitTestSource) return;

        const hitTestResults = frame.getHitTestResults(hitTestSource);
        if (hitTestResults.length > 0) {
          const pose = hitTestResults[0].getPose(referenceSpace);
          const position = new THREE.Vector3().fromArray(pose.transform.position.toArray());
          const rotation = new THREE.Quaternion().fromArray(pose.transform.orientation.toArray());

          fadeOutInstruction();
          fadeHeadphoneIn();
          setTimeout(() => {
            loadModel(position, rotation);
          }, 6000); // wait for headphone display sequence
        }
      });

      scene.add(controller);

      renderer.setAnimationLoop(() => {
        const delta = clock.getDelta();
        if (mixer) mixer.update(delta);
        renderer.render(scene, camera);
      });
    }

    // Load ARButton script and start
    const script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/webxr/ARButton.js';
    script.onload = init;
    document.head.appendChild(script);
  </script>
</body>
</html>
